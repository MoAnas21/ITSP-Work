{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\moham\\anaconda3\\lib\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "curses is not supported on this machine (please install/reinstall curses for an optimal experience)\n"
     ]
    }
   ],
   "source": [
    "import tflearn\n",
    "from tflearn.layers.conv import conv_2d, max_pool_2d\n",
    "from tflearn.layers.core import input_data, dropout, fully_connected\n",
    "from tflearn.layers.estimator import regression\n",
    "from tensorflow.python.framework import ops\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from IPython.display import clear_output\n",
    "import tkinter\n",
    "import PIL.Image, PIL.ImageTk\n",
    "import time\n",
    "import threading\n",
    "import tweepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyVideoCapture:\n",
    "    def __init__(self, video_source=0):\n",
    "         # Open the video source\n",
    "        self.vid = cv2.VideoCapture(video_source)\n",
    "        if not self.vid.isOpened():\n",
    "            raise ValueError(\"Unable to open video source\", video_source)\n",
    " \n",
    "         # Get video source width and height\n",
    "        self.width = self.vid.get(cv2.CAP_PROP_FRAME_WIDTH)\n",
    "        self.height = self.vid.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
    " \n",
    "    def get_frame(self):\n",
    "        if self.vid.isOpened():\n",
    "            ret, frame = self.vid.read()\n",
    "            if ret:\n",
    "                # Return a boolean success flag and the current frame converted to BGR\n",
    "                return (ret, cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "            else:\n",
    "                return (ret, None)\n",
    "        else:\n",
    "            return (ret, None)\n",
    " \n",
    "     # Release the video source when the object is destroyed\n",
    "    def __del__(self):\n",
    "        if self.vid.isOpened():\n",
    "            self.vid.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class face_reg:\n",
    "    def __init__(self):\n",
    "        self.make_model()\n",
    "        \n",
    "    def face_detection(self,img):\n",
    "        face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        face_cordinates = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "        faces = []\n",
    "        if len(face_cordinates)>0:\n",
    "            no_of_faces = face_cordinates.shape[0]\n",
    "        else:\n",
    "            no_of_faces = 0\n",
    "        for i in range(no_of_faces):\n",
    "            faces.append(img[face_cordinates[i][1]:face_cordinates[i][1]+face_cordinates[i][3],face_cordinates[i][0]:face_cordinates[i][0]+face_cordinates[i][2],:])\n",
    "        return faces\n",
    "    \n",
    "    def get_data(self,name,cap):\n",
    "        i = 1\n",
    "        try:\n",
    "            path = os.curdir + \"/data/\" + name\n",
    "            os.mkdir(path) \n",
    "        except FileExistsError:\n",
    "            print(\"Data with the name \" , name ,  \" already exists\")\n",
    "            return\n",
    "        while(i<100):\n",
    "            ret,frame = cap.get_frame()\n",
    "            faces = self.face_detection(frame)\n",
    "            if len(faces)>0:\n",
    "                faces[0] = cv2.cvtColor(faces[0], cv2.COLOR_BGR2GRAY)\n",
    "                cv2.imwrite(path + \"/\" + str(i) + \".jpg\",faces[0])\n",
    "                i = i+1\n",
    "        self.make_model()\n",
    "        return\n",
    "\n",
    "    def make_model(self):\n",
    "        names = os.listdir(\"Data\")\n",
    "        train_images = np.empty((0,50,50,1), dtype=np.float64)\n",
    "        temp_array = np.empty((50,50,1), dtype=np.float64)\n",
    "        train_labels = np.empty((0,len(names)),dtype=np.uint8)\n",
    "        label_array = np.empty((len(names)), dtype=np.uint8)\n",
    "        no_data = 0\n",
    "        for i in range(len(names)):\n",
    "            images = os.listdir(\"Data/\" + names[i])\n",
    "            label_array = [0 for i in range(len(names))]\n",
    "            label_array[i] = 1 \n",
    "            for j in range(len(images)):\n",
    "                clear_output(True)\n",
    "                print(str(no_data))\n",
    "                img = cv2.imread(\"Data/\" + names[i] + \"/\" + images[j], 1)\n",
    "                img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "                img = cv2.resize(img,(50,50))\n",
    "                temp_array[:,:,0] = img\n",
    "                train_images = np.append(train_images,np.array([temp_array]),axis=0)\n",
    "                train_labels = np.append(train_labels,np.array([label_array]),axis=0)\n",
    "                no_data = no_data + 1\n",
    "        train_images = train_images\n",
    "        \n",
    "        ops.reset_default_graph()\n",
    "        convnet = input_data(shape=[50,50,1])\n",
    "        convnet = conv_2d(convnet, 32, 5, activation='relu')\n",
    "        convnet = max_pool_2d(convnet, 5)\n",
    "        convnet = conv_2d(convnet, 64, 5, activation='relu')\n",
    "        convnet = max_pool_2d(convnet, 5)\n",
    "        convnet = conv_2d(convnet, 128, 5, activation='relu')\n",
    "        convnet = max_pool_2d(convnet, 5)\n",
    "        convnet = conv_2d(convnet, 64, 5, activation='relu')\n",
    "        convnet = max_pool_2d(convnet, 5)\n",
    "        convnet = conv_2d(convnet, 32, 5, activation='relu')\n",
    "        convnet = max_pool_2d(convnet, 5)\n",
    "\n",
    "        convnet = fully_connected(convnet, 1024, activation='relu')\n",
    "        convnet = dropout(convnet, 0.8)\n",
    "        convnet = fully_connected(convnet, len(names), activation='softmax')\n",
    "        convnet = regression(convnet, optimizer='adam', learning_rate = 0.001, loss='categorical_crossentropy')\n",
    "        self.model = tflearn.DNN(convnet, tensorboard_verbose=1)\n",
    "        self.history = self.model.fit(train_images, train_labels, n_epoch=15, show_metric = True, run_id=\"FRS\" )\n",
    "        return\n",
    "    \n",
    "    def recognise(self,cap):\n",
    "        names = os.listdir(\"Data\")\n",
    "        temp_array = np.empty((50,50,1), dtype=np.float64)\n",
    "        i = 0\n",
    "        j = 0\n",
    "        while(i<200):\n",
    "            ret,frame = cap.get_frame()\n",
    "            faces = self.face_detection(frame)\n",
    "            if len(faces)>0:\n",
    "                img = cv2.cvtColor(faces[0], cv2.COLOR_BGR2GRAY)\n",
    "                img = cv2.resize(img,(50,50))\n",
    "                temp_array[:,:,0] = img\n",
    "                self.predictions = self.model.predict([temp_array])\n",
    "                if np.max(self.predictions[0])>0.8:\n",
    "                    j = j+1\n",
    "                    if j>=3:\n",
    "                        return names[np.argmax(self.predictions[0])]\n",
    "            i = i+1\n",
    "            cv2.waitKey(20)\n",
    "        return \"Not recognised\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 44  | total loss: \u001b[1m\u001b[32m0.56585\u001b[0m\u001b[0m | time: 0.192s\n",
      "| Adam | epoch: 015 | loss: 0.56585 - acc: 0.8337 -- iter: 128/183\n",
      "Training Step: 45  | total loss: \u001b[1m\u001b[32m0.47959\u001b[0m\u001b[0m | time: 0.290s\n",
      "| Adam | epoch: 015 | loss: 0.47959 - acc: 0.8619 -- iter: 183/183\n",
      "--\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.App at 0x1da0a014ee0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class App:\n",
    "    def __init__(self, window, window_title, video_source=0):\n",
    "        self.window = window\n",
    "        self.window.title(window_title)\n",
    "        self.video_source = video_source\n",
    "        \n",
    "        self.pwthaut = [\"Anas\"]\n",
    " \n",
    "        # Open video source (by default this will try to open the computer webcam)\n",
    "        self.vid = MyVideoCapture(self.video_source)\n",
    "        \n",
    "        self.freg = face_reg()\n",
    "        \n",
    "        self.t1 = threading.Thread(target=self.aut)\n",
    "        self.t2 = threading.Thread(target=self.gd)\n",
    "        \n",
    "        self.autst = \"Not Authorised\"\n",
    " \n",
    "        # Create a canvas that can fit the above video source size\n",
    "        self.canvas = tkinter.Canvas(window, width = self.vid.width, height = self.vid.height)\n",
    "        self.canvas.pack()\n",
    "        \n",
    "        self.output_field=tkinter.Label(window, text = \"Hello\")\n",
    "        self.output_field.pack(anchor=tkinter.CENTER, expand=True)\n",
    " \n",
    "        # Button 1\n",
    "        self.btn_snapshot=tkinter.Button(window, text=\"Authorise\", width=50, command=self.t1.start)\n",
    "        self.btn_snapshot.pack(anchor=tkinter.CENTER, expand=True)\n",
    "        \n",
    "        tkinter.Label(self.window,text=\"Enter Name\").pack(anchor=tkinter.CENTER, expand=True)\n",
    "        self.input_field=tkinter.Entry(window)\n",
    "        self.input_field.pack(anchor=tkinter.CENTER, expand=True)\n",
    "        \n",
    "        # Button 2\n",
    "        self.btn_snapshot=tkinter.Button(window, text=\"Get Data\", width=50, command=self.t2.start)\n",
    "        self.btn_snapshot.pack(anchor=tkinter.CENTER, expand=True)\n",
    "        \n",
    "        self.output_field_end=tkinter.Label(window)\n",
    "        self.output_field_end.pack(anchor=tkinter.CENTER, expand=True)\n",
    "        \n",
    "         # After it is called once, the update method will be automatically called every delay milliseconds\n",
    "        self.delay = 10\n",
    "        self.update()\n",
    " \n",
    "        self.window.mainloop()\n",
    "    \n",
    "    def aut(self):\n",
    "        self.acc = self.freg.recognise(self.vid)\n",
    "        if self.acc in self.pwthaut:\n",
    "            self.autst = \"Authorised\"\n",
    "            self.output_field.configure(text = \"Authorised\")\n",
    "        else:\n",
    "            self.output_field.configure(text = \"Not Authorised\")\n",
    "        \n",
    "    def gd(self):\n",
    "        self.freg.get_data(self.input_field.get(),self.vid)\n",
    "        self.output_field_end.configure(text = \"Data Aquired\")\n",
    "        \n",
    "    def tweet(self):\n",
    "        #my twitter account's key, if you use this keys, tweets will be posted in my account\n",
    "        #So make a twitter account, apply for developer profile... then you will get the keys\n",
    "        consumer_key = \"g8CXca2B3q9dq2DsVWi7L3xEZ\"\n",
    "        consumer_secret = \"qCyMR2D4BEiI7Uuhmv1rredpj2lhQxCL4hHPa3iliWlle1nMv7\"\n",
    "        access_token = \"1410950779913990144-husWMAhCKJskjfVwug1Wb9PZ32qZPI\"\n",
    "        access_token_secret = \"wTVr17ilI6XkgesNwUaazYtKQB4vy0E665Zjve1gY8qer\"\n",
    "\n",
    "        auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "\n",
    "        auth.set_access_token(access_token, access_token_secret)\n",
    "        api = tweepy.API(auth)\n",
    "\n",
    "        api.update_status(status = self.input_field_tw.get(\"1.0\",tkinter.END))\n",
    "        \n",
    "        timenow = time.ctime(time.time())\n",
    "        self.output_field_cnfm1.configure(text = \"Tweeted by \"+self.acc)\n",
    "        self.output_field_cnfm2.configure(text = \"At time \"+timenow)\n",
    "        self.fout = open(\"Tweet.txt\", 'w')\n",
    "        self.fout.write(self.input_field_tw.get(\"1.0\",tkinter.END))\n",
    "        self.fout.close()\n",
    "        self.fout = open(\"Log.txt\", 'a')\n",
    "        self.fout.write(self.acc+\" \"+timenow+\"\\n\")\n",
    "        self.fout.close()\n",
    "        \n",
    "        \n",
    "    def newupdate(self):\n",
    "        for widgets in self.window.winfo_children():\n",
    "             widgets.pack_forget()\n",
    "        \n",
    "        tkinter.Label(self.window,text=\"Enter Tweet\").pack()\n",
    "        self.input_field_tw=tkinter.Text(self.window,font= \"Helvetica 15 bold\",height=10,width=80)\n",
    "        self.input_field_tw.pack(anchor=tkinter.CENTER)\n",
    "        \n",
    "        #tkinter.Label(self.window,text=\"Enter Time\").place(x=100,y=100)\n",
    "        #self.input_field_tm=tkinter.Entry(self.window)\n",
    "        #self.input_field_tm.place(anchor=tkinter.CENTER,x = 300,y = 100)\n",
    "        \n",
    "        self.btn_snapshot=tkinter.Button(self.window, text=\"Confirm\", width=50, command=self.tweet)\n",
    "        self.btn_snapshot.pack(anchor=tkinter.CENTER)\n",
    "        \n",
    "        self.output_field_cnfm1=tkinter.Label(self.window)\n",
    "        self.output_field_cnfm1.pack(anchor=tkinter.CENTER)\n",
    "        \n",
    "        self.output_field_cnfm2=tkinter.Label(self.window)\n",
    "        self.output_field_cnfm2.pack(anchor=tkinter.CENTER)\n",
    "        \n",
    "        self.window.mainloop()\n",
    "            \n",
    "\n",
    "    def update(self):\n",
    "         # Get a frame from the video source\n",
    "        ret, frame = self.vid.get_frame()\n",
    " \n",
    "        if ret and self.autst == \"Not Authorised\":\n",
    "            self.photo = PIL.ImageTk.PhotoImage(image = PIL.Image.fromarray(frame))\n",
    "            self.canvas.create_image(0, 0, image = self.photo, anchor = tkinter.NW)\n",
    "        if self.autst == \"Authorised\":\n",
    "            self.newupdate()\n",
    " \n",
    "        self.window.after(self.delay, self.update)\n",
    "    \n",
    " \n",
    " # Create a window and pass it to the Application object\n",
    "App(tkinter.Tk(), \"Twitter BOT\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
